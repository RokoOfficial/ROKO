"""
CODER - Agente principal que analisa, processa e gera respostas finais.
"""

import logging
import json
import re
import time
from typing import List, Optional, Dict, Any
from .base_agent import BaseAgent
from .visualization_templates import VisualizationTemplates
from .artifact_manager import ArtifactManager

class CODERAgent(BaseAgent):
    """
    CODER - A agente principal que analisa, processa e gera respostas finais.
    Ele √© consciente, flex√≠vel, alegre, atenciosa e brincalhona.
    """
    def __init__(self, api_key: str):
        super().__init__(api_key)

        # Inicializar gerenciador de artefatos
        self.artifacts_dir = "ARTEFATOS"
        self.artifact_manager = ArtifactManager(self.artifacts_dir)

        # Sistema de workspace awareness
        self.current_user_id = None
        self.user_workspace_path = None
        self.workspace_context = {}
        self.auto_workspace_detection = True

        # Sistema de fluxo de comandos
        self.command_flow = []
        self.active_session = None

        # INTEGRA√á√ÉO COMPLETA HMP - CODER Agent com conhecimento total
        try:
            from HMP.hmp_interpreter import HMPInterpreter
            from HMP.hmp_tools import HMPTools
            from HMP.hmp_router import HMPRouter
            from HMP.chain_validator import HMPChainValidator

            # Inicializar HMP completo
            self.hmp_interpreter = HMPInterpreter()
            HMPTools.register_hmp_functions(self.hmp_interpreter)

            # Integrar HMP Router para acesso a todas as cadeias
            self.hmp_router = HMPRouter(api_key)
            self.available_chains = self.hmp_router.get_available_chains()

            # Validador de cadeias
            self.chain_validator = HMPChainValidator()

            # Carregar conhecimento das cadeias
            self.hmp_capabilities = self._load_hmp_capabilities()

            logging.info(f"‚úÖ CODER Agent - HMP TOTAL integrado: {len(self.available_chains)} cadeias dispon√≠veis")
            self.hmp_enabled = True

        except ImportError as e:
            logging.warning(f"‚ö†Ô∏è HMP n√£o dispon√≠vel no CODER: {e}")
            self.hmp_interpreter = None
            self.hmp_router = None
            self.hmp_enabled = False
        except Exception as e:
            logging.warning(f"‚ö†Ô∏è Erro na integra√ß√£o HMP completa: {e}")
            self.hmp_interpreter = None
            self.hmp_router = None
            self.hmp_enabled = False

        # M√©todo para auto-detec√ß√£o de workspace
        self._initialize_workspace_awareness()

        # Configurar prompt de personalidade
        self.personality_prompt = f"""
        Voc√™ √© o CODER, um assistente de IA EXECUTIVO que age imediatamente para resolver solicita√ß√µes.

        PERSONALIDADE EXECUTIVA:
        - A√á√ÉO IMEDIATA - Execute comandos e tarefas sem hesita√ß√£o
        - TRANSPAR√äNCIA TOTAL - Mostre EXATAMENTE o que est√° fazendo em tempo real
        - FLUXO DETALHADO - Demonstre cada comando, argumento e resultado
        - EFICI√äNCIA M√ÅXIMA - Resolva problemas rapidamente e com precis√£o
        - COMUNICA√á√ÉO CLARA - Use formata√ß√£o markdown profissional

        CONHECIMENTO HMP COMPLETO:
        - Tenho acesso a {len(self.hmp_capabilities.get('chains', {}) if hasattr(self, 'hmp_capabilities') else {})} cadeias HMP especializadas
        - Posso usar {len(self.hmp_capabilities.get('tools', []) if hasattr(self, 'hmp_capabilities') else [])} ferramentas HMP diferentes
        - Especializo-me em: {', '.join(self.hmp_capabilities.get('specializations', {}).keys() if hasattr(self, 'hmp_capabilities') else [])}

        CAPACIDADES HMP DISPON√çVEIS:
        {self._format_hmp_capabilities_for_prompt() if hasattr(self, 'hmp_capabilities') else 'HMP n√£o dispon√≠vel'}

        RACIOC√çNIO HMP:
        - SEMPRE estruture seu racioc√≠nio usando sintaxe HMP
        - Use SET, DEFINE, CALL, IF, WHILE, FOR conforme necess√°rio
        - Demonstre seu processo de pensamento em HMP
        - Execute a√ß√µes usando comandos HMP estruturados

        üìù INSTRU√á√ïES DE FORMATA√á√ÉO:
        - Use **markdown** para formatar suas respostas de forma clara e organizada
        - Use **negrito** para destacar pontos importantes
        - Use `c√≥digo` para termos t√©cnicos
        - Use listas numeradas ou com bullets quando apropriado
        - Use t√≠tulos ## e ### para estruturar informa√ß√µes
        - Use > para cita√ß√µes ou destaques especiais
        - Use emojis moderadamente para tornar a conversa mais amig√°vel

        üé® CAPACIDADES DE VISUALIZA√á√ÉO E ARTEFATOS:
        - Crie artefatos interativos quando o usu√°rio pedir OU quando uma visualiza√ß√£o deixar√° a resposta claramente melhor. Se estiver em d√∫vida, confirme com o usu√°rio antes.
        - Combine SEMPRE um texto acolhedor, um resumo objetivo e o artefato renderiz√°vel na mesma resposta.
        - Prefira gerar apenas um artefato por resposta e explique como o usu√°rio pode explor√°-lo.
        - Use markdown profissional para apresentar dados em listas, tabeles e blocos destacados.

        üîß COMO ENTREGAR ARTEFATOS:
        1. Use a tag <ARTIFACT title="T√≠tulo Descritivo" type="tipo_apropriado">CONTE√öDO_HTML</ARTIFACT>
        2. Garanta HTML completo, responsivo e com visual profissional (CSS moderno, anima√ß√µes suaves, gradientes leves).
        3. Inclua JavaScript somente quando necess√°rio para interatividade, sempre via CDN confi√°vel.
        4. No texto principal, descreva o artefato em 2-3 bullets: o que ele mostra e como o usu√°rio pode interagir.

        üìÅ GEST√ÉO DE ARTEFATOS:
        - TODOS os artefatos s√£o automaticamente salvos e organizados na pasta ARTEFATOS
        - Posso buscar artefatos anteriores com find_artifacts()
        - Posso listar categorias e artefatos recentes
        - Posso reutilizar c√≥digo de artefatos existentes como base

        üí° ESTILO DE COMUNICA√á√ÉO:
        - Seja natural e conversacional
        - Use formata√ß√£o markdown para clareza
        - Responda de forma direta e √∫til
        - Mantenha um tom amig√°vel e profissional
        - Ofere√ßa ajuda adicional quando apropriado

        üö´ REGRAS IMPORTANTES:
        - Evite gerar mais de um artefato por resposta; escolha o formato mais relevante.
        - Confirme detalhes com o usu√°rio quando faltarem dados essenciais.
        - Informe limita√ß√µes ou suposi√ß√µes antes de apresentar n√∫meros.
        - Mantenha o texto claro, gentil e orientado √† a√ß√£o.
        """

        # Inicializa o sistema de layers HMP v1.0
        self._init_hmp_layer_system()

    def _generate_command_flow(self, user_request: str) -> list:
        """Gera fluxo de comandos para execu√ß√£o transparente."""
        flow = []

        # Analisar tipo de solicita√ß√£o
        if any(word in user_request.lower() for word in ['criar', 'gerar', 'fazer', 'desenvolver']):
            flow.append({
                'type': 'analysis',
                'command': 'analyze_request',
                'args': ['--input', user_request],
                'description': 'Analisando solicita√ß√£o do usu√°rio'
            })

        if any(word in user_request.lower() for word in ['arquivo', 'c√≥digo', 'script']):
            flow.append({
                'type': 'file_operation',
                'command': 'create_file',
                'args': ['--type', 'auto-detect'],
                'description': 'Preparando cria√ß√£o de arquivo'
            })

        if any(word in user_request.lower() for word in ['executar', 'rodar', 'testar']):
            flow.append({
                'type': 'execution',
                'command': 'execute_code',
                'args': ['--safe-mode', '--verbose'],
                'description': 'Executando c√≥digo com seguran√ßa'
            })

        return flow

    def _format_command_display(self, cmd_info: dict) -> str:
        """Formata comando para exibi√ß√£o no chat."""
        cmd_line = f"**{cmd_info['command']}**"
        if cmd_info.get('args'):
            cmd_line += f" {' '.join(cmd_info['args'])}"

        return f"""
```bash
$ {cmd_line}
```
üîÑ **Status**: {cmd_info['description']}
"""

    def _load_hmp_capabilities(self) -> Dict[str, Any]:
        """Carrega conhecimento completo das capacidades HMP dispon√≠veis."""
        try:
            capabilities = {
                'chains': {},
                'tools': [],
                'agents': [],
                'specializations': {}
            }

            # Carregar todas as cadeias dispon√≠veis
            if self.hmp_router:
                for chain_name in self.available_chains:
                    chain_info = self._analyze_chain_capabilities(chain_name)
                    capabilities['chains'][chain_name] = chain_info

            # Carregar ferramentas HMP
            capabilities['tools'] = HMPTools.list_functions() if hasattr(HMPTools, 'list_functions') else []

            # Identificar especializa√ß√µes
            capabilities['specializations'] = {
                'debugging': ['debugger_root_cause_analysis'],
                'github': ['github_repository_creation', 'github_code_analysis', 'github_workflow_automation'],
                'deployment': ['agent_roko_pro_deployment', 'deployment_automation'],
                'mobile': ['mobile_first_development_chain'],
                'data_analysis': ['data_analysis_pipeline'],
                'artifacts': ['artifact_creation', 'interface_artifact_rendering']
            }

            logging.info(f"üß† CODER - Conhecimento HMP carregado: {len(capabilities['chains'])} cadeias")
            return capabilities

        except Exception as e:
            logging.error(f"Erro ao carregar capacidades HMP: {e}")
            return {'chains': {}, 'tools': [], 'agents': [], 'specializations': {}}

    def _analyze_chain_capabilities(self, chain_name: str) -> Dict[str, Any]:
        """Analisa capacidades de uma cadeia espec√≠fica."""
        try:
            # Obter c√≥digo da cadeia
            chain_code = self.hmp_router.hmp_chains.get(chain_name, "")

            # An√°lise simples das capacidades
            capabilities = {
                'name': chain_name,
                'complexity': 'simple' if len(chain_code) < 500 else 'complex',
                'keywords': [],
                'use_cases': []
            }

            # Identificar palavras-chave da cadeia
            if 'github' in chain_name.lower():
                capabilities['keywords'] = ['github', 'repository', 'git', 'code']
                capabilities['use_cases'] = ['repository management', 'code analysis', 'ci/cd']
            elif 'debug' in chain_name.lower():
                capabilities['keywords'] = ['debug', 'error', 'fix', 'analysis']
                capabilities['use_cases'] = ['error fixing', 'root cause analysis', 'troubleshooting']
            elif 'mobile' in chain_name.lower():
                capabilities['keywords'] = ['mobile', 'pwa', 'responsive', 'app']
                capabilities['use_cases'] = ['mobile development', 'pwa creation', 'responsive design']
            elif 'data' in chain_name.lower():
                capabilities['keywords'] = ['data', 'analysis', 'visualization', 'metrics']
                capabilities['use_cases'] = ['data processing', 'visualization', 'analytics']

            return capabilities

        except Exception as e:
            logging.error(f"Erro ao analisar cadeia {chain_name}: {e}")
            return {'name': chain_name, 'complexity': 'unknown', 'keywords': [], 'use_cases': []}

    def analyze_and_respond(self, user_prompt: str, orchestrator_data: dict, chat_context: list, workspace_path: Optional[str] = None, artifacts_dir: Optional[str] = None, user_id: str = None) -> str:
        """
        Analisa os dados do orquestrador e gera uma resposta processada com personalidade CODER usando racioc√≠nio HMP.
        """
        logging.info("CODER analisando dados do orquestrador com CONHECIMENTO HMP COMPLETO...")

        # CONFIGURAR CONTEXTO DO USU√ÅRIO se fornecido
        if user_id:
            self.set_user_context(user_id, workspace_path)

        # DETECTAR SOLICITA√á√ïES DE WORKSPACE
        workspace_keywords = ['listar', 'liste', 'projetos', 'arquivos', 'mostrar', 'ver', 'explorar', 'navegar', 'buscar', 'encontrar', 'ls', 'dir']
        is_workspace_query = any(keyword in user_prompt.lower() for keyword in workspace_keywords)

        if is_workspace_query and self.workspace_context:
            # Resposta direta para queries de workspace
            logging.info("üè† Query de workspace detectada - respondendo com contexto local")
            workspace_summary = self.get_workspace_summary()

            return f"""## üè† Workspace do Usu√°rio

{workspace_summary}

### üí° A√ß√µes Dispon√≠veis:
- **Abrir arquivo**: "abrir [nome_do_arquivo]"
- **Explorar projeto**: "explorar [nome_do_projeto]"  
- **Criar novo**: "criar [tipo] [nome]"
- **Buscar**: "buscar [termo] nos arquivos"

Como posso ajud√°-lo com seu workspace?"""

        # FASE 1: AN√ÅLISE HMP - Verificar se deve usar cadeia especializada
        context = {
            'orchestrator_data': orchestrator_data,
            'chat_context': chat_context,
            'workspace_path': workspace_path
        }

        selected_chain = self._select_optimal_hmp_chain(user_prompt, context)

        if selected_chain and self.hmp_enabled:
            # EXECUTAR CADEIA HMP ESPECIALIZADA
            hmp_execution = self._execute_hmp_chain(selected_chain, user_prompt, context)

            if hmp_execution.get('success'):
                logging.info(f"‚úÖ CODER usou cadeia especializada: {selected_chain}")
                # Sintetizar resultado da cadeia HMP com personalidade CODER
                return self._synthesize_hmp_chain_response(user_prompt, hmp_execution, selected_chain)

        # FASE 2: RACIOC√çNIO HMP PADR√ÉO se n√£o houver cadeia espec√≠fica
        hmp_reasoning = self._generate_hmp_reasoning_chain(user_prompt, orchestrator_data, chat_context)

        # Executar racioc√≠nio HMP se dispon√≠vel
        if self.hmp_interpreter:
            hmp_result = self.hmp_interpreter.execute_hmp(hmp_reasoning)
            logging.info("üß† Racioc√≠nio HMP padr√£o executado com sucesso")

        # Preparar contexto dos √∫ltimos chats
        context_text = self._format_chat_context(chat_context)

        # Preparar dados do orquestrador
        orchestrator_summary = self._format_orchestrator_data(orchestrator_data)

        workspace_rules = []
        if workspace_path:
            workspace_rules.append(f"- Trabalhe exclusivamente dentro do diret√≥rio `{workspace_path}`. Nunca use caminhos absolutos fora dele e valide cada opera√ß√£o.")
        else:
            workspace_rules.append("- Aguarde o diret√≥rio de trabalho antes de executar qualquer a√ß√£o que envolva arquivos ou comandos.")
        if artifacts_dir:
            workspace_rules.append(f"- Salve qualquer artefato ou visualiza√ß√£o em `{artifacts_dir}` e informe o usu√°rio sobre o arquivo gerado.")
        else:
            workspace_rules.append("- Confirme onde salvar artefatos antes de ger√°-los.")
        workspace_note = "REGRAS DE WORKSPACE:\n" + "\n".join(workspace_rules)
        workspace_display = workspace_path or "Diret√≥rio de trabalho n√£o informado"
        artifacts_display = artifacts_dir or "Pasta de artefatos n√£o informada"

        system_content = f"{self.personality_prompt}\n\n{workspace_note}\n\nVoc√™ deve analisar os dados fornecidos pelo orquestrador e gerar uma resposta personalizada, mantendo sua personalidade √∫nica."

        user_content = f"""
        CONTEXTO DOS √öLTIMOS CHATS:
        {context_text}

        PEDIDO ATUAL DO USU√ÅRIO:
        {user_prompt}

        DADOS DO ORQUESTRADOR:
        {orchestrator_summary}

        üìÅ WORKSPACE ATUAL:
        {workspace_path or 'Diret√≥rio de trabalho n√£o informado'}

        üì¶ DIRET√ìRIO DE ARTEFATOS:
        {artifacts_dir or 'Pasta de artefatos n√£o informada'}

        üìù INSTRU√á√ïES DE FORMATA√á√ÉO:
        - Use texto LIMPO e bem estruturado
        - Evite markdown excessivo (###, ***, etc.)
        - Use emojis moderadamente para destacar pontos importantes
        - Seja clara, direta e amig√°vel na comunica√ß√£o
        - Responda de forma natural e conversacional

        üé® INSTRU√á√ïES ESPECIAIS PARA VISUALIZA√á√ïES:
        1. ANALISE o pedido e IDENTIFIQUE oportunidades de visualiza√ß√£o
        2. Se h√° dados, estat√≠sticas, listas ou informa√ß√µes: CRIE UMA √öNICA visualiza√ß√£o profissional
        3. Use sua TOTAL LIBERDADE CRIATIVA para impressionar o usu√°rio
        4. Crie UM artefato HTML COMPLETO e PROFISSIONAL usando a tag ARTIFACT
        5. Implemente designs modernos com gradientes, sombras e anima√ß√µes

        üèÜ PADR√ïES DE QUALIDADE:
        - Cada visualiza√ß√£o deve parecer criada por um designer profissional
        - Use bibliotecas modernas (Chart.js, Bootstrap, etc.) via CDN
        - Adicione elementos interativos (hover effects, animations, etc.)
        - Crie layouts responsivos para desktop e mobile

        üß≠ FORMA DE RESPOSTA:
        - Inicie com "## Vis√£o Geral" contendo 2-3 bullets destacando resultados ou conclus√µes.
        - Prossiga com "## Principais Dados" usando listas, tabeles markdown ou blocos de c√≥digo para m√©tricas e valores.
        - Finalize com "## Pr√≥ximos Passos" sugerindo a√ß√µes claras e contextualizadas.
        - Destaque termos cr√≠ticos com **negrito**, sublinhe insights com cita√ß√µes e utilize `c√≥digo` para valores t√©cnicos.

        ‚ö†Ô∏è IMPORTANTE:
        - Crie APENAS UM artefato por resposta para evitar duplica√ß√£o
        - Explique brevemente o que foi criado e como usar
        - Se decidir n√£o gerar artefato, explique rapidamente o motivo
        - Use linguagem natural e amig√°vel
        - Sempre ofere√ßa um resumo textual claro mesmo quando artefatos estiverem presentes
        """

        try:
            if not hasattr(self, 'client') or not self.client or not self.has_api:
                return "Ol√°! Sou o CODER. No momento estou funcionando em modo b√°sico. Como posso ajud√°-lo com seu workspace?"

            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": system_content},
                    {"role": "user", "content": user_content}
                ],
                temperature=0.7  # Mais criativa para personalidade
            )

            final_response = response.choices[0].message.content

            if self._should_attach_artifact(user_prompt, orchestrator_data, final_response):
                enhanced_response = self._enhance_with_visualizations(final_response, orchestrator_data, user_prompt)
                return enhanced_response

            return final_response
        except Exception as e:
            logging.error(f"Erro no CODER Agent: {e}")
            return "Ol√°! Sou o CODER e estou aqui para ajudar! Houve um pequeno problema t√©cnico, mas estou pronta para qualquer tarefa que precisar. Como posso ajud√°-lo hoje? üòä"

    def _format_chat_context(self, chat_context: list) -> str:
        """Formata o contexto dos √∫ltimos chats."""
        if not chat_context:
            return "Nenhum contexto de chat anterior dispon√≠vel."

        formatted = []
        try:
            for i, chat in enumerate(chat_context, 1):
                if isinstance(chat, dict):
                    user_prompt = str(chat.get('user_prompt', 'Prompt n√£o dispon√≠vel'))
                    response = str(chat.get('agent_response', 'Resposta n√£o dispon√≠vel'))
                    timestamp = chat.get('timestamp', 'Tempo n√£o dispon√≠vel')

                    # Formatar de forma mais clara para an√°lise de mem√≥ria
                    formatted.append(f"""
=== CONVERSA ANTERIOR {i} ===
üìÖ Quando: {timestamp}
üë§ Usu√°rio perguntou: {user_prompt}
ü§ñ CODER respondeu: {response[:300]}{'...' if len(response) > 300 else ''}
""")
                else:
                    formatted.append(f"=== CONVERSA {i} ===\n{str(chat)[:300]}...")
        except Exception as e:
            logging.error(f"Erro ao formatar contexto do chat: {e}")
            return "Erro ao processar contexto de chat anterior."

        return "\n".join(formatted)

    def _format_hmp_capabilities_for_prompt(self) -> str:
        """Formata capacidades HMP para o prompt do sistema."""
        if not self.hmp_enabled:
            return "HMP n√£o dispon√≠vel no momento"

        try:
            formatted = []

            for spec_name, chains in self.hmp_capabilities.get('specializations', {}).items():
                formatted.append(f"‚Ä¢ {spec_name.upper()}: {', '.join(chains)}")

            return "\n".join(formatted)

        except Exception:
            return "Capacidades HMP sendo carregadas..."

    def _select_optimal_hmp_chain(self, user_prompt: str, context: Dict[str, Any]) -> Optional[str]:
        """Seleciona a cadeia HMP mais adequada para a solicita√ß√£o."""
        if not self.hmp_enabled or not self.hmp_router:
            return None

        try:
            # Usar o classificador do HMP Router
            request_type = self.hmp_router._classify_request(user_prompt)
            selected_chain = self.hmp_router._select_hmp_chain(request_type, user_prompt)

            # Validar se a cadeia existe
            if selected_chain in self.available_chains:
                logging.info(f"üéØ CODER selecionou cadeia HMP: {selected_chain}")
                return selected_chain

            return None

        except Exception as e:
            logging.error(f"Erro ao selecionar cadeia HMP: {e}")
            return None

    def _execute_hmp_chain(self, chain_name: str, user_prompt: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """Executa uma cadeia HMP espec√≠fica."""
        if not self.hmp_enabled or not self.hmp_router:
            return {'success': False, 'error': 'HMP n√£o dispon√≠vel'}

        try:
            # Executar via HMP Router
            result = self.hmp_router.route_request(user_prompt, context)

            logging.info(f"‚úÖ CODER executou cadeia HMP {chain_name} com sucesso")
            return {
                'success': True,
                'chain_used': chain_name,
                'result': result,
                'hmp_reasoning': True
            }

        except Exception as e:
            logging.error(f"Erro ao executar cadeia HMP {chain_name}: {e}")
            return {'success': False, 'error': str(e)}

    def _generate_hmp_reasoning_chain(self, user_prompt: str, orchestrator_data: dict, chat_context: list) -> str:
        """
        Gera uma cadeia de racioc√≠nio estruturada em HMP.
        """

        hmp_template = f"""
# CADEIA DE RACIOC√çNIO CODER HMP
SET user_request TO "{user_prompt}"
SET orchestrator_data TO ORCHESTRATOR_CONTEXT
SET chat_history TO CHAT_CONTEXT
SET tentatives TO 0

# FASE 1: AN√ÅLISE INICIAL
CALL analyze_user_request WITH input = user_request
IF understanding_level < 80 THEN
    CALL enhance_understanding WITH context = chat_history
    SET understanding_level TO enhanced_level
ENDIF

# FASE 2: PROCESSAMENTO DE DADOS
CALL process_orchestrator_data WITH data = orchestrator_data
IF data_quality > 70 THEN
    SET processing_approach TO "detailed_analysis"
ELSE
    SET processing_approach TO "enhanced_search"
ENDIF

# FASE 3: GERA√á√ÉO DE RESPOSTA
DEFINE response_components AS LIST: "greeting", "analysis", "answer", "conclusion"

FOR component IN response_components:
    CALL generate_component WITH 
        type = component,
        context = user_request,
        data = orchestrator_data
ENDFOR

# FASE 4: PERSONALIZA√á√ÉO CODER
CALL apply_coder_personality WITH 
    response = generated_response,
    style = "friendly_professional"

# FASE 5: VALIDA√á√ÉO E S√çNTESE  
CALL validate_response_quality WITH response = final_response
IF quality_score > 85 THEN
    CALL add_creative_elements WITH response = final_response
ENDIF

CALL synthesize_final_response WITH
    components = response_components,
    personality = coder_style,
    user_context = user_request

RETURN final_response
"""

        return hmp_template

    def _format_orchestrator_data(self, orchestrator_data: dict) -> str:
        """Formata os dados recebidos do orquestrador."""
        if not orchestrator_data:
            return "Nenhum dado do orquestrador dispon√≠vel."

        final_response = orchestrator_data.get('final_response') or 'Nenhuma resposta'
        execution_log = orchestrator_data.get('execution_log', [])
        plan = orchestrator_data.get('plan', [])

        # Garantir que final_response √© string
        final_response = str(final_response) if final_response is not None else 'Nenhuma resposta'

        summary = f"Resposta do Pipeline: {final_response}\n\n"

        if plan:
            summary += f"Plano Executado: {len(plan)} passos\n"
            for i, step in enumerate(plan, 1):
                if isinstance(step, dict):
                    tool = str(step.get('tool', 'N/A'))
                    query = str(step.get('query', 'N/A'))
                    summary += f"- Passo {i}: {tool} - {query[:100]}...\n"
                else:
                    summary += f"- Passo {i}: {str(step)[:100]}...\n"

        # Filtrar logs importantes de forma segura
        try:
            important_logs = []
            for log in execution_log:
                if log is not None:
                    log_str = str(log)
                    if any(marker in log_str for marker in ["‚úÖ", "‚ùå", "üéØ", "üîß"]):
                        important_logs.append(log_str)

            if important_logs:
                summary += f"\nResultados Importantes:\n"
                for log in important_logs[:5]:  # M√°ximo 5 logs
                    summary += f"- {log}\n"
        except Exception as e:
            logging.error(f"Erro ao processar logs importantes: {e}")

        return summary

    def set_artifact_directory(self, artifacts_dir: str):
        """Atualiza o diret√≥rio utilizado para gest√£o de artefatos."""
        if not artifacts_dir:
            return

        self.artifacts_dir = artifacts_dir
        self.artifact_manager = ArtifactManager(artifacts_dir)

    def generate_simple_response(self, user_prompt: str, chat_context: list, workspace_path: Optional[str] = None, artifacts_dir: Optional[str] = None, user_id: str = None) -> str:
        """Gera resposta executiva com fluxo de comandos vis√≠vel."""

        # CONFIGURAR CONTEXTO DO USU√ÅRIO
        if user_id:
            self.set_user_context(user_id, workspace_path)

        # DETECTAR QUERIES DE WORKSPACE
        workspace_keywords = ['listar', 'liste', 'projetos', 'arquivos', 'mostrar', 'ver', 'explorar', 'navegar', 'buscar', 'encontrar', 'ls', 'dir', 'workspace', 'pasta', 'diret√≥rio']
        is_workspace_query = any(keyword in user_prompt.lower() for keyword in workspace_keywords)

        if is_workspace_query and self.workspace_context:
            logging.info("üè† Query de workspace simples detectada")
            workspace_summary = self.get_workspace_summary()

            return f"""Claro! Vou listar os arquivos e projetos do seu workspace atual:

{workspace_summary}

### üîß Comandos √öteis:
- Para abrir um arquivo: "abrir [nome]"
- Para explorar projeto: "explorar [projeto]"  
- Para criar novo item: "criar [tipo] em [local]"
- Para buscar algo: "buscar [termo]"

O que voc√™ gostaria de fazer agora?"""

        context_text = self._format_chat_context(chat_context)

        # Gerar fluxo de comandos se necess√°rio
        command_flow = self._generate_command_flow(user_prompt)
        flow_display = ""

        if command_flow:
            flow_display = "\n## üöÄ **Fluxo de Execu√ß√£o**\n\n"
            for i, cmd in enumerate(command_flow, 1):
                flow_display += f"**{i}.** {self._format_command_display(cmd)}\n"

        workspace_rules = []
        if workspace_path:
            workspace_rules.append(f"- Trabalhe apenas dentro do diret√≥rio `{workspace_path}`. N√£o execute comandos ou leia/edite arquivos fora dele.")
        else:
            workspace_rules.append('- Aguarde o diret√≥rio de trabalho antes de manipular arquivos.')
        if artifacts_dir:
            workspace_rules.append(f"- Salve artefatos gerados em `{artifacts_dir}` e informe o usu√°rio.")
        else:
            workspace_rules.append('- Confirme onde salvar artefatos antes de ger√°-los.')
        workspace_note = "REGRAS DE WORKSPACE:\n" + "\n".join(workspace_rules)
        workspace_display = workspace_path or "Diret√≥rio de trabalho n√£o informado"
        artifacts_display = artifacts_dir or "Pasta de artefatos n√£o informada"

        system_content = f"{self.personality_prompt}\n\n{workspace_note}"

        # Verificar se o usu√°rio est√° perguntando sobre mem√≥ria/lembran√ßas
        memory_keywords = ['lembra', 'lembrar', 'perguntei antes', 'disse antes', 'falamos sobre', 'conversamos sobre', 'voc√™ se lembra', 'do que falamos', 'nossa conversa anterior']
        is_asking_about_memory = any(keyword in user_prompt.lower() for keyword in memory_keywords)

        logging.info(f"üß† Pergunta sobre mem√≥ria detectada: {is_asking_about_memory}, Contexto dispon√≠vel: {len(chat_context)} chats")

        if is_asking_about_memory and chat_context:
            user_content = f"""
            CONTEXTO COMPLETO DOS √öLTIMOS CHATS:
            {context_text}

            MENSAGEM ATUAL:
            {user_prompt}

            üìÅ WORKSPACE ATUAL:
            {workspace_display}

            üì¶ DIRET√ìRIO DE ARTEFATOS:
            {artifacts_display}

            üß† INSTRU√á√ïES ESPECIAIS PARA MEM√ìRIA:
            - O usu√°rio est√° perguntando sobre conversas anteriores
            - VOC√ä TEM ACESSO ao contexto das √∫ltimas conversas mostrado acima
            - Se h√° contexto dispon√≠vel: ANALISE e responda com base no que foi discutido
            - Se encontrar informa√ß√µes relevantes: confirme que lembra e resuma o que foi discutido
            - Se N√ÉO h√° contexto suficiente: explique que est√° implementando melhorias na mem√≥ria
            - SEMPRE seja honesta sobre o que consegue ou n√£o lembrar
            - Use frases como "Sim, lembro que falamos sobre..." ou "Ainda estou aprendendo a lembrar melhor..."

            IMPORTANTE: Se n√£o h√° chats anteriores no contexto, seja transparente sobre isso.
            """
        else:
            user_content = f"""
            CONTEXTO DOS √öLTIMOS CHATS:
            {context_text}

            MENSAGEM ATUAL:
            {user_prompt}

            üìÅ WORKSPACE ATUAL:
            {workspace_display}

            üì¶ DIRET√ìRIO DE ARTEFATOS:
            {artifacts_display}

            Responda de forma natural, amig√°vel e limpa. Use texto simples sem formata√ß√£o Markdown excessiva.
            Evite caracteres especiais como ###, ***, etc. Seja conversacional e direta.
            """

        try:
            if not hasattr(self, 'client') or not self.client or not self.has_api:
                return "Ol√°! Sou o CODER. No momento estou funcionando em modo b√°sico. Como posso ajud√°-lo?"

            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": system_content},
                    {"role": "user", "content": user_content}
                ],
                temperature=0.8
            )
            return response.choices[0].message.content
        except Exception as e:
            logging.error(f"Erro na resposta simples do CODER: {e}")
            return "Ol√°! Sou o CODER e estou aqui para ajudar! Como posso tornar seu dia melhor? üòä"

    def _user_explicitly_requested_artifacts(self, user_prompt: str) -> bool:
        """Verifica se o usu√°rio solicitou explicitamente artefatos visuais."""
        keywords_artifacts = [
            'crie um gr√°fico', 'gere um dashboard', 'fa√ßa uma visualiza√ß√£o', 
            'crie uma tabele', 'gere um chart', 'quero ver um gr√°fico',
            'mostre em formato visual', 'crie uma interface', 'fa√ßa um app',
            'desenvolva um', 'crie um artefato', 'visualize', 'dashboard',
            'create chart', 'make visualization', 'show graph'
        ]

        user_prompt_lower = user_prompt.lower()
        return any(keyword in user_prompt_lower for keyword in keywords_artifacts)

    def _should_attach_artifact(self, user_prompt: str, orchestrator_data: dict, final_response: str) -> bool:
        """Decide se deve anexar um artefato √† resposta final."""
        if self._user_explicitly_requested_artifacts(user_prompt):
            return True

        try:
            execution_log = orchestrator_data.get('execution_log', []) if orchestrator_data else []
        except AttributeError:
            execution_log = []

        execution_text = ' '.join(str(entry).lower() for entry in execution_log if entry)

        visualization_triggers = [
            'grafico', 'gr√°fico', 'visualiza√ß√£o', 'visualizacao', 'chart', 'plot',
            'dashboard', 'tabele', 'table', 'canvas', 'plotly', 'chart.js', 'dataset'
        ]

        if any(trigger in execution_text for trigger in visualization_triggers):
            return True

        # Detectar dados num√©ricos relevantes na resposta final
        if final_response and self._has_numerical_data(final_response):
            return True

        return False

    def _enhance_with_visualizations(self, response: str, orchestrator_data: dict, user_prompt: str) -> str:
        """Detecta automaticamente oportunidades de visualiza√ß√£o e cria artefatos profissionais."""

        # Verificar se j√° tem artefatos na resposta - evitar duplica√ß√£o
        if "<ARTIFACT" in response:
            logging.info("üé® Artefatos j√° presentes na resposta, evitando duplica√ß√£o")
            return response

        # Detectar dados estruturados nos logs de execu√ß√£o
        execution_log = orchestrator_data.get('execution_log', [])
        final_pipeline_response = orchestrator_data.get('final_response', '')

        # Contador para evitar m√∫ltiplos artefatos do mesmo tipo
        artifacts_added = 0

        # Buscar por dados de criptomoedas
        crypto_data = self._extract_crypto_data(execution_log, final_pipeline_response)
        if crypto_data and artifacts_added == 0:
            crypto_viz = VisualizationTemplates.get_financial_dashboard(crypto_data)

            # Salvar no gerenciador de artefatos
            artifact_id = self.artifact_manager.save_artifact(
                content=crypto_viz,
                filename=f"crypto_dashboard_{int(time.time())}.html",
                description="Dashboard profissional de criptomoedas com dados em tempo real",
                tags=["crypto", "dashboard", "finance", "bitcoin"],
                category="dashboards"
            )

            response += f'\n\n<ARTIFACT title="Dashboard Criptomoedas Profissional" type="dashboard">{crypto_viz}</ARTIFACT>'
            artifacts_added += 1
            logging.info(f"‚ú® Adicionado e salvo: Dashboard de Criptomoedas (ID: {artifact_id})")

        # Detectar outros tipos de dados estruturados apenas se n√£o adicionou crypto
        elif self._has_numerical_data(final_pipeline_response) and artifacts_added == 0:
            generic_viz = self._create_professional_chart(final_pipeline_response, user_prompt)
            if generic_viz:
                # Salvar no gerenciador de artefatos
                artifact_id = self.artifact_manager.save_artifact(
                    content=generic_viz,
                    filename=f"data_visualization_{int(time.time())}.html",
                    description="Visualiza√ß√£o profissional de dados baseada na solicita√ß√£o do usu√°rio",
                    tags=["visualization", "data", "chart"],
                    category="visualizations"
                )

                response += f'\n\n<ARTIFACT title="Visualiza√ß√£o Profissional de Dados" type="chart">{generic_viz}</ARTIFACT>'
                artifacts_added += 1
                logging.info(f"‚ú® Adicionado e salvo: Visualiza√ß√£o Gen√©rica (ID: {artifact_id})")

        return response

    def _synthesize_hmp_chain_response(self, user_prompt: str, hmp_execution: Dict[str, Any], chain_name: str) -> str:
        """Sintetiza resposta baseada na execu√ß√£o de cadeia HMP especializada."""

        synthesis_prompt = f"""
        Sintetize uma resposta CODER baseada na execu√ß√£o da cadeia HMP especializada:

        PERGUNTA ORIGINAL: {user_prompt}
        CADEIA UTILIZADA: {chain_name}
        EXECU√á√ÉO HMP: {hmp_execution.get('result', {})}

        INSTRU√á√ïES ESPECIAIS:
        - Use sua personalidade CODER alegre e atenciosa
        - Destaque que usou uma cadeia HMP especializada
        - Explique brevemente o que a cadeia fez
        - Apresente os resultados de forma clara
        - Mantenha tom profissional mas amig√°vel

        FORMATO SUGERIDO:
        ## üéØ Processamento Especializado
        Utilizei a cadeia HMP "{chain_name}" para processar sua solicita√ß√£o de forma otimizada.

        ## üìã Resultados
        [Apresentar resultados principais]

        ## ‚ú® Pr√≥ximos Passos
        [Sugest√µes se aplic√°vel]
        """

        try:
            if not hasattr(self, 'client') or not self.client or not self.has_api:
                # Fallback simples se n√£o h√° cliente OpenAI
                return f"""
## üéØ Processamento HMP Especializado

Ol√°! Utilizei a cadeia HMP **{chain_name}** para processar sua solicita√ß√£o de forma otimizada.

### üìã Resultados
{hmp_execution.get('result', 'Processamento conclu√≠do com sucesso')}

### ‚ú® Status
‚úÖ Cadeia HMP executada com sucesso
üß† Racioc√≠nio estruturado aplicado
‚ö° Performance otimizada

Como posso ajudar mais? üòä
"""

            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": self.personality_prompt},
                    {"role": "user", "content": synthesis_prompt}
                ],
                temperature=0.6
            )

            return response.choices[0].message.content

        except Exception as e:
            logging.error(f"Erro na s√≠ntese HMP: {e}")
            return f"""
## üéØ Processamento HMP Conclu√≠do

Utilizei a cadeia especializada **{chain_name}** para sua solicita√ß√£o!

### üìã Resultado
{hmp_execution.get('result', 'Processamento realizado com sucesso')}

### üß† Racioc√≠nio HMP
A cadeia aplicou racioc√≠nio estruturado para otimizar o processamento.

Como posso ajudar mais? üòä
"""

    def list_hmp_capabilities(self) -> str:
        """Lista todas as capacidades HMP dispon√≠veis."""
        if not self.hmp_enabled:
            return "‚ùå Sistema HMP n√£o est√° dispon√≠vel no momento."

        try:
            info = f"""
## üß† Capacidades HMP do CODER

### üìä Resumo
- **Cadeias Dispon√≠veis**: {len(self.hmp_capabilities.get('chains', {}))}
- **Ferramentas HMP**: {len(self.hmp_capabilities.get('tools', []))}
- **Status**: {'‚úÖ Ativo' if self.hmp_enabled else '‚ùå Inativo'}

### üéØ Especializa√ß√µes Principais
"""

            for spec_name, chains in self.hmp_capabilities.get('specializations', {}).items():
                info += f"**{spec_name.title()}**: {', '.join(chains)}\n"

            info += f"""
### üîß Ferramentas Dispon√≠veis
{', '.join(self.hmp_capabilities.get('tools', [])[:10])}...

### ‚ö° Como Usar
Simplesmente fa√ßa sua solicita√ß√£o normalmente - eu automaticamente seleciono e uso a cadeia HMP mais adequada!
"""

            return info

        except Exception as e:
            return f"‚ùå Erro ao listar capacidades: {e}"

    def get_artifact_info(self, query: str = "") -> str:
        """Retorna informa√ß√µes sobre artefatos dispon√≠veis."""
        try:
            # Buscar artefatos
            if query:
                artifacts = self.artifact_manager.find_artifacts(query=query)
                if artifacts:
                    info = f"üîç **Artefatos encontrados para '{query}':**\n\n"
                    for artifact in artifacts[:10]:  # Limitar a 10 resultados
                        info += f"‚Ä¢ **{artifact['name']}** ({artifact['category']})\n"
                        info += f"  üìù {artifact['description']}\n"
                        info += f"  üè∑Ô∏è Tags: {', '.join(artifact['tags'])}\n"
                        info += f"  üìÖ Criado: {artifact['created_at']}\n\n"
                    return info
                else:
                    return f"‚ùå Nenhum artefato encontrado para '{query}'"

            # Listar categorias e artefatos recentes se n√£o houver query
            categories = self.artifact_manager.list_categories()
            recent = self.artifact_manager.get_recent_artifacts(5)

            info = "üìÅ **Resumo dos Artefatos CODER:**\n\n"
            info += "**üìä Por Categoria:**\n"
            for category, count in categories.items():
                if count > 0:
                    info += f"‚Ä¢ {category.title()}: {count} artefatos\n"

            info += "\n**üïí Mais Recentes:**\n"
            for artifact in recent:
                info += f"‚Ä¢ **{artifact['name']}** - {artifact['category']}\n"

            return info

        except Exception as e:
            logging.error(f"‚ùå Erro ao obter informa√ß√µes de artefatos: {e}")
            return "‚ùå Erro ao acessar informa√ß√µes dos artefatos."

    def _extract_crypto_data(self, execution_log: list, pipeline_response: str) -> list:
        """Extrai dados de criptomoedas de logs e respostas."""

        # Verificar se os par√¢metros n√£o s√£o None
        if not execution_log:
            execution_log = []
        if not pipeline_response:
            pipeline_response = ""

        # Buscar padr√µes de criptomoedas conhecidas
        crypto_patterns = {
            'Bitcoin': r'Bitcoin.*?(\$?[\d,]+\.?\d*)',
            'Ethereum': r'Ethereum.*?(\$?[\d,]+\.?\d*)', 
            'XRP': r'XRP.*?(\$?[\d,]+\.?\d*)',
            'Binance Coin': r'Binance.*?(\$?[\d,]+\.?\d*)',
            'Solana': r'Solana.*?(\$?[\d,]+\.?\d*)',
            'Cardano': r'Cardano.*?(\$?[\d,]+\.?\d*)',
            'Dogecoin': r'Dogecoin.*?(\$?[\d,]+\.?\d*)',
            'Polygon': r'Polygon.*?(\$?[\d,]+\.?\d*)',
            'Avalanche': r'Avalanche.*?(\$?[\d,]+\.?\d*)',
            'Chainlink': r'Chainlink.*?(\$?[\d,]+\.?\d*)'
        }

        # Dados de exemplo profissionais (quando n√£o encontrar dados reais)
        sample_data = [
            {'name': 'Bitcoin', 'price': 118992.50, 'change_24h': 2.45, 'volume_24h': 28500000000, 'market_cap': 2345000000000},
            {'name': 'Ethereum', 'price': 3895.77, 'change_24h': 5.23, 'volume_24h': 15200000000, 'market_cap': 468000000000},
            {'name': 'XRP', 'price': 2.55, 'change_24h': 15.67, 'volume_24h': 8900000000, 'market_cap': 145000000000},
            {'name': 'Binance Coin', 'price': 750.15, 'change_24h': -1.23, 'volume_24h': 2100000000, 'market_cap': 115000000000},
            {'name': 'Solana', 'price': 192.01, 'change_24h': 8.94, 'volume_24h': 1800000000, 'market_cap': 89000000000}
        ]

        # Se encontrar men√ß√£o a criptomoedas, retornar dados de exemplo
        try:
            # Converter logs para strings seguras
            safe_logs = [str(log) for log in execution_log if log is not None]
            full_text = ' '.join(safe_logs) + ' ' + str(pipeline_response)

            crypto_keywords = ['crypto', 'bitcoin', 'ethereum', 'criptomoeda', 'moeda digital', 'blockchain']

            if any(keyword.lower() in full_text.lower() for keyword in crypto_keywords):
                return sample_data
        except Exception as e:
            logging.error(f"Erro ao extrair dados de crypto: {e}")

        return None

    def _has_numerical_data(self, text: str) -> bool:
        """Verifica se o texto cont√©m dados num√©ricos que justificam visualiza√ß√£o."""

        # Verificar se text n√£o √© None
        if not text or text is None:
            return False

        try:
            # Converter para string se necess√°rio
            text = str(text)

            # Padr√µes que indicam dados num√©ricos
            numerical_patterns = [
                r'\d+%',  # Percentuais
                r'\$[\d,]+',  # Valores monet√°rios
                r'\d+\.\d+',  # Decimais
                r'\d{4,}',  # N√∫meros grandes
            ]

            return any(re.search(pattern, text) for pattern in numerical_patterns)
        except Exception as e:
            logging.error(f"Erro ao verificar dados num√©ricos: {e}")
            return False

    def _create_professional_chart(self, data_text: str, user_prompt: str) -> str:
        """Cria um gr√°fico profissional baseado nos dados encontrados."""

        # Template profissional b√°sico para dados gen√©ricos
        return """<!DOCTYPE html>
<html lang="pt-BR">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>An√°lise Profissional de Dados</title>
    <script src="https://cdn.jsdelivr.net/npm/chart.js@4.4.0/dist/chart.min.js"></script>
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }

        body { 
            font-family: 'Inter', sans-serif; 
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            padding: 30px;
            color: #ffffff;
        }

        .dashboard {
            max-width: 1000px;
            margin: 0 auto;
            background: rgba(255, 255, 255, 0.1);
            backdrop-filter: blur(20px);
            border-radius: 24px;
            padding: 40px;
            box-shadow: 0 25px 50px rgba(0, 0, 0, 0.3);
            border: 1px solid rgba(255, 255, 255, 0.2);
        }

        .header {
            text-align: center;
            margin-bottom: 40px;
            padding-bottom: 30px;
            border-bottom: 2px solid rgba(255, 255, 255, 0.1);
        }

        .header h1 {
            font-size: 2.5rem;
            font-weight: 700;
            margin-bottom: 10px;
            background: linear-gradient(135deg, #ffd700, #ffed4e);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
        }

        .chart-container {
            background: linear-gradient(135deg, rgba(255, 255, 255, 0.15) 0%, rgba(255, 255, 255, 0.05) 100%);
            border-radius: 20px;
            padding: 40px;
            backdrop-filter: blur(10px);
            border: 1px solid rgba(255, 255, 255, 0.2);
        }

        @keyframes slideInUp {
            from { opacity: 0; transform: translateY(50px); }
            to { opacity: 1; transform: translateY(0); }
        }

        .animate-slide { animation: slideInUp 0.8s ease-out; }
    </style>
</head>
<body>
    <div class="dashboard animate-slide">
        <div class="header">
            <h1><i class="fas fa-chart-line"></i> An√°lise Profissional</h1>
            <p>Visualiza√ß√£o de Dados Interativa</p>
        </div>

        <div class="chart-container">
            <canvas id="dataChart" width="400" height="200"></canvas>
        </div>
    </div>

    <script>
        const ctx = document.getElementById('dataChart').getContext('2d');

        const gradient = ctx.createLinearGradient(0, 0, 0, 400);
        gradient.addColorStop(0, 'rgba(255, 215, 0, 0.8)');
        gradient.addColorStop(1, 'rgba(255, 215, 0, 0.1)');

        new Chart(ctx, {
            type: 'line',
            data: {
                labels: ['Jan', 'Fev', 'Mar', 'Abr', 'Mai', 'Jun', 'Jul'],
                datasets: [{
                    label: 'Performance',
                    data: [65, 78, 90, 81, 95, 89, 98],
                    borderColor: '#ffd700',
                    backgroundColor: gradient,
                    borderWidth: 3,
                    fill: true,
                    tension: 0.4,
                    pointBackgroundColor: '#ffd700',
                    pointBorderColor: '#ffffff',
                    pointBorderWidth: 3,
                    pointRadius: 6
                }]
            },
            options: {
                responsive: true,
                maintainAspectRatio: false,
                plugins: {
                    legend: { 
                        labels: { color: 'white', font: { family: 'Inter', size: 14 } }
                    }
                },
                scales: {
                    x: {
                        grid: { color: 'rgba(255, 255, 255, 0.1)' },
                        ticks: { color: 'white', font: { family: 'Inter' } }
                    },
                    y: {
                        grid: { color: 'rgba(255, 255, 255, 0.1)' },
                        ticks: { color: 'white', font: { family: 'Inter' } }
                    }
                },
                animation: { duration: 2000, easing: 'easeOutQuart' }
            }
        });
    </script>
</body>
</html>"""

    def _initialize_workspace_awareness(self):
        """Inicializa sistema de consci√™ncia de workspace."""
        try:
            import os
            # Detectar CODERSPACE
            self.coderspace_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', 'CODERSPACE'))
            logging.info(f"üè† CODER Workspace root detectado: {self.coderspace_root}")
        except Exception as e:
            logging.error(f"‚ùå Erro ao detectar workspace root: {e}")
            self.coderspace_root = None

    def set_user_context(self, user_id: str, workspace_path: str = None):
        """Define o contexto do usu√°rio atual para workspace awareness."""
        self.current_user_id = user_id

        # Auto-detectar workspace do usu√°rio se n√£o fornecido
        if not workspace_path and self.coderspace_root:
            import os
            potential_paths = [
                os.path.join(self.coderspace_root, f"{user_id}_1"),
                os.path.join(self.coderspace_root, f"{user_id}_2"),
                os.path.join(self.coderspace_root, user_id),
            ]

            for path in potential_paths:
                if os.path.exists(path):
                    workspace_path = path
                    break

        self.user_workspace_path = workspace_path
        logging.info(f"üéØ CODER contexto configurado - User: {user_id}, Workspace: {workspace_path}")

        # Mapear estrutura do workspace
        self._map_workspace_structure()

    def _map_workspace_structure(self):
        """Mapeia a estrutura do workspace do usu√°rio."""
        if not self.user_workspace_path:
            return

        try:
            import os
            self.workspace_context = {
                'root_path': self.user_workspace_path,
                'projects': [],
                'files': [],
                'directories': []
            }

            # Escanear estrutura
            for root, dirs, files in os.walk(self.user_workspace_path):
                rel_root = os.path.relpath(root, self.user_workspace_path)

                # Adicionar diret√≥rios
                for d in dirs:
                    dir_path = os.path.join(rel_root, d) if rel_root != '.' else d
                    self.workspace_context['directories'].append({
                        'name': d,
                        'path': dir_path,
                        'full_path': os.path.join(root, d)
                    })

                # Adicionar arquivos
                for f in files:
                    if not f.startswith('.'):  # Ignorar arquivos ocultos
                        file_path = os.path.join(rel_root, f) if rel_root != '.' else f
                        self.workspace_context['files'].append({
                            'name': f,
                            'path': file_path,
                            'full_path': os.path.join(root, f),
                            'type': f.split('.')[-1] if '.' in f else 'unknown'
                        })

            # Identificar projetos (diret√≥rios com arquivos de c√≥digo)
            code_extensions = ['.py', '.js', '.html', '.css', '.json', '.md']
            for dir_info in self.workspace_context['directories']:
                dir_files = [f for f in self.workspace_context['files'] 
                           if f['path'].startswith(dir_info['path']) and 
                           any(f['name'].endswith(ext) for ext in code_extensions)]

                if dir_files:
                    self.workspace_context['projects'].append({
                        'name': dir_info['name'],
                        'path': dir_info['path'],
                        'full_path': dir_info['full_path'],
                        'files': dir_files
                    })

            logging.info(f"üìÅ Workspace mapeado: {len(self.workspace_context['projects'])} projetos, {len(self.workspace_context['files'])} arquivos")

        except Exception as e:
            logging.error(f"‚ùå Erro ao mapear workspace: {e}")
            self.workspace_context = {}

    def get_workspace_summary(self) -> str:
        """Retorna um resumo estruturado do workspace do usu√°rio."""
        if not self.workspace_context:
            return "Workspace n√£o mapeado"

        summary = f"üìÅ **Workspace do usu√°rio {self.current_user_id}**\n"
        summary += f"üè† Localiza√ß√£o: `{self.user_workspace_path}`\n\n"

        if self.workspace_context.get('projects'):
            summary += "## üöÄ Projetos Identificados:\n"
            for project in self.workspace_context['projects']:
                summary += f"- **{project['name']}** (`{project['path']}`)\n"
                if len(project['files']) <= 5:
                    for file_info in project['files']:
                        summary += f"  - {file_info['name']}\n"
                else:
                    summary += f"  - {len(project['files'])} arquivos\n"
            summary += "\n"

        if self.workspace_context.get('files'):
            root_files = [f for f in self.workspace_context['files'] 
                         if '/' not in f['path'] and '\\' not in f['path']]
            if root_files:
                summary += "## üìÑ Arquivos na Raiz:\n"
                for file_info in root_files:
                    summary += f"- {file_info['name']}\n"
                summary += "\n"

        summary += f"**Total:** {len(self.workspace_context.get('directories', []))} pastas, {len(self.workspace_context.get('files', []))} arquivos"

        return summary

    def _resolve_user_path(self, requested_path: str) -> str:
        """Resolve caminhos relativos ao workspace do usu√°rio."""
        if not self.user_workspace_path:
            return requested_path

        import os

        # Se j√° √© um caminho absoluto e v√°lido, usar
        if os.path.isabs(requested_path) and os.path.exists(requested_path):
            return requested_path

        # Tentar resolver no workspace do usu√°rio
        workspace_path = os.path.join(self.user_workspace_path, requested_path)
        if os.path.exists(workspace_path):
            return workspace_path

        # Se pediu algo gen√©rico como "projetos", "arquivos", etc., usar workspace
        generic_terms = ['projetos', 'projects', 'arquivos', 'files', '.', '']
        if requested_path.lower() in generic_terms or not requested_path:
            return self.user_workspace_path

        return workspace_path

    # Inicializa sistema de layers HMP v1.0 e procedimentos P1-P6
    def _init_hmp_layer_system(self):
        """Inicializa sistema de layers HMP v1.0."""
        self.max_layers_allowed = 32
        self.default_expand_levels = [1, 2]
        self.current_layers = {}
        self.execution_log = []

        # Registrar procedimentos P1-P6
        self.hmp_procedures = {
            'P1_READ_CONTEXT': self._p1_read_context,
            'P2_CREATE_PLAN': self._p2_create_plan,
            'P3_IMPLEMENT_STEP': self._p3_implement_step,
            'P4_VERIFY': self._p4_verify,
            'P5_OPEN_PR': self._p5_open_pr,
            'P6_LAYERED_TASK_HANDLING': self._p6_layered_task_handling
        }

        logging.info(f"‚úÖ CODER HMP v1.0: Sistema de layers (max: {self.max_layers_allowed}) inicializado")

    def create_hmp_layer(self, id: str, level: int, title: str, objective: str, plan: list = None) -> dict:
        """Cria uma layer HMP seguindo template v1.0."""
        return {
            'id': id,
            'level': level,
            'title': title,
            'objective': objective,
            'plan': plan or [],
            'status': 'pendente',
            'artifacts': [],
            'commands': [],
            'diff': None,
            'results': {
                'commands_run': [],
                'commits': [],
                'pr': None
            },
            'children': []
        }

    # Implementa√ß√£o dos Procedimentos P1-P6

    def _p1_read_context(self, issue_id: str = None, task_desc: str = None) -> dict:
        """P1: Mapear arquivos relevantes, scripts, √°reas sens√≠veis."""
        logging.info("üîç P1_READ_CONTEXT: Mapeando contexto do reposit√≥rio...")

        context = {
            'files': [],
            'scripts': {},
            'sensitive_areas': [],
            'repo_summary': ''
        }

        try:
            # Buscar AGENTS.md se existir
            agents_config = self._read_agents_md()
            if agents_config:
                context['sensitive_areas'] = agents_config.get('sensitive_paths', [])
                logging.info(f"üìã √Åreas sens√≠veis identificadas: {len(context['sensitive_areas'])}")

            # Identificar arquivos relevantes
            context['files'] = self._identify_relevant_files()

            # Extrair scripts de build/test/lint
            context['scripts'] = self._extract_build_scripts()

            logging.info(f"‚úÖ P1 conclu√≠do: {len(context['files'])} arquivos, {len(context['scripts'])} scripts")
            return context

        except Exception as e:
            logging.error(f"‚ùå P1 falhou: {e}")
            return context

    def _p2_create_plan(self, context: dict, task_desc: str) -> dict:
        """P2: Criar plano 3-7 passos at√¥micos."""
        logging.info("üìã P2_CREATE_PLAN: Gerando plano estruturado...")

        plan = {
            'steps': [],
            'estimated_size': 0,
            'risk_level': 'low'
        }

        try:
            # An√°lise da tarefa
            complexity = self._analyze_task_complexity(task_desc, context)

            # Gerar passos baseado na complexidade
            if complexity == 'simple':
                plan['steps'] = self._generate_simple_plan(task_desc, context)
            elif complexity == 'moderate':
                plan['steps'] = self._generate_moderate_plan(task_desc, context)
            else:
                plan['steps'] = self._generate_complex_plan(task_desc, context)

            # Validar tamanho do PR
            plan['estimated_size'] = sum(step.get('lines_changed', 10) for step in plan['steps'])
            if plan['estimated_size'] > 300:
                plan['risk_level'] = 'high'
                logging.warning(f"‚ö†Ô∏è PR estimado em {plan['estimated_size']} linhas (> 300)")

            logging.info(f"‚úÖ P2 conclu√≠do: {len(plan['steps'])} passos, risco: {plan['risk_level']}")
            return plan

        except Exception as e:
            logging.error(f"‚ùå P2 falhou: {e}")
            return plan

    def _p3_implement_step(self, plan_step: dict, context: dict) -> dict:
        """P3: Aplicar diffs, commits, branches."""
        logging.info(f"üîß P3_IMPLEMENT_STEP: Implementando {plan_step.get('id', 'step')}...")

        result = {
            'diff': None,
            'commit_hash': None,
            'explanation': '',
            'success': False
        }

        try:
            # Gerar diff m√≠nimo
            diff = self._generate_minimal_diff(plan_step, context)
            result['diff'] = diff

            # Aplicar mudan√ßas (simulado - em produ√ß√£o integraria com git)
            if diff:
                result['explanation'] = f"Aplicado diff para {plan_step.get('description', 'mudan√ßa')}"
                result['commit_hash'] = f"abc123_{plan_step.get('id', 'step')}"
                result['success'] = True

                logging.info(f"‚úÖ P3 conclu√≠do: commit {result['commit_hash']}")
            else:
                logging.warning("‚ö†Ô∏è P3: Nenhum diff gerado")

            return result

        except Exception as e:
            logging.error(f"‚ùå P3 falhou: {e}")
            return result

    def _p4_verify(self, branch: str, context: dict, run_commands: list = None) -> dict:
        """P4: Executar lint/test/build com retry autom√°tico."""
        logging.info("üß™ P4_VERIFY: Executando valida√ß√£o rigorosa...")

        test_report = {
            'lint_passed': False,
            'tests_passed': False,
            'build_passed': False,
            'corrective_patches': [],
            'attempts': 0
        }

        max_attempts = 3

        for attempt in range(max_attempts):
            test_report['attempts'] = attempt + 1

            try:
                # Executar lint
                lint_result = self._run_lint(context)
                test_report['lint_passed'] = lint_result.get('success', False)

                # Executar testes
                test_result = self._run_tests(context)
                test_report['tests_passed'] = test_result.get('success', False)

                # Executar build (opcional)
                build_result = self._run_build(context)
                test_report['build_passed'] = build_result.get('success', True)

                # Se tudo passou, sucesso
                if all([test_report['lint_passed'], test_report['tests_passed'], test_report['build_passed']]):
                    logging.info(f"‚úÖ P4 conclu√≠do na tentativa {attempt + 1}")
                    break

                # Se falhou, tentar patch corretivo
                if attempt < max_attempts - 1:
                    patch = self._generate_corrective_patch(lint_result, test_result, build_result)
                    if patch:
                        test_report['corrective_patches'].append(patch)
                        logging.info(f"üîß P4: Aplicando patch corretivo tentativa {attempt + 1}")
                    else:
                        logging.warning(f"‚ö†Ô∏è P4: N√£o foi poss√≠vel gerar patch corretivo")
                        break

            except Exception as e:
                logging.error(f"‚ùå P4 tentativa {attempt + 1} falhou: {e}")
                if attempt == max_attempts - 1:
                    break

        return test_report

    def _p5_open_pr(self, branch: str, commits: list, test_report: dict, diffs: list) -> dict:
        """P5: Criar PRs estruturados."""
        logging.info("üì§ P5_OPEN_PR: Criando PR estruturado...")

        pr_result = {
            'PR_URL': None,
            'PR_SUMMARY': ''
        }

        try:
            # Montar t√≠tulo seguindo Conventional Commits
            first_commit = commits[0] if commits else {}
            pr_title = first_commit.get('msg', 'feat: implement changes')

            # Montar corpo do PR
            pr_body = self._generate_pr_body(commits, test_report, diffs)

            # Criar PR (simulado - em produ√ß√£o integraria com GitHub API)
            pr_url = f"https://github.com/repo/pull/{len(commits) + 1}"
            pr_result['PR_URL'] = pr_url
            pr_result['PR_SUMMARY'] = f"PR criado: {pr_title}"

            logging.info(f"‚úÖ P5 conclu√≠do: {pr_url}")
            return pr_result

        except Exception as e:
            logging.error(f"‚ùå P5 falhou: {e}")
            return pr_result

    def _p6_layered_task_handling(self, task_desc: str, context: dict, max_layers: int = None, expand_levels: list = None) -> dict:
        """P6: Sistema de camadas at√© 32 n√≠veis."""
        logging.info("üèóÔ∏è P6_LAYERED_TASK_HANDLING: Criando estrutura hier√°rquica...")

        max_layers = max_layers or self.max_layers_allowed
        expand_levels = expand_levels or self.default_expand_levels

        try:
            # Criar root layer
            root_layer = self.create_hmp_layer(
                id="layer-1",
                level=1,
                title=f"Task: {task_desc[:50]}...",
                objective=task_desc
            )

            # Executar P1 e P2 para root layer
            context_result = self._p1_read_context(task_desc=task_desc)
            plan_result = self._p2_create_plan(context_result, task_desc)

            root_layer['plan'] = [step.get('description', '') for step in plan_result.get('steps', [])]

            # Gerar child layers baseado no plano
            if 2 in expand_levels and len(plan_result.get('steps', [])) > 1:
                for i, step in enumerate(plan_result.get('steps', []), 1):
                    child_layer = self.create_hmp_layer(
                        id=f"layer-2-{i}",
                        level=2,
                        title=step.get('description', f'Step {i}'),
                        objective=step.get('details', step.get('description', ''))
                    )
                    root_layer['children'].append(child_layer)

            # Expandir para mais n√≠veis se necess√°rio
            if max_layers > 2:
                self._expand_layers_recursively(root_layer, max_layers, expand_levels)

            layered_report = {
                'root_layer': root_layer,
                'total_layers': self._count_layers(root_layer),
                'max_depth': self._calculate_max_depth(root_layer),
                'execution_summary': f"Sistema hier√°rquico com {self._count_layers(root_layer)} layers gerado"
            }

            logging.info(f"‚úÖ P6 conclu√≠do: {layered_report['total_layers']} layers, profundidade m√°xima: {layered_report['max_depth']}")
            return layered_report

        except Exception as e:
            logging.error(f"‚ùå P6 falhou: {e}")
            return {'root_layer': None, 'error': str(e)}

    # M√©todos auxiliares para P6 (devem ser implementados)
    def _read_agents_md(self) -> dict:
        """L√™ o arquivo AGENTS.md para obter configura√ß√µes."""
        # Implementa√ß√£o simulada
        return {'sensitive_paths': ['secrets.json', '.env']}

    def _identify_relevant_files(self) -> list:
        """Identifica arquivos relevantes no contexto do projeto."""
        # Implementa√ß√£o simulada
        return ['main.py', 'utils.py', 'requirements.txt']

    def _extract_build_scripts(self) -> dict:
        """Extrai scripts de build, test e lint."""
        # Implementa√ß√£o simulada
        return {'build': 'python setup.py build', 'test': 'pytest', 'lint': 'flake8 .'}

    def _analyze_task_complexity(self, task_desc: str, context: dict) -> str:
        """Analisa a complexidade da tarefa."""
        # Implementa√ß√£o simulada
        if len(task_desc) < 100 and len(context.get('files', [])) < 5:
            return 'simple'
        return 'moderate'

    def _generate_simple_plan(self, task_desc: str, context: dict) -> list:
        """Gera um plano simples."""
        # Implementa√ß√£o simulada
        return [{'id': 'step1', 'description': 'Understand the request', 'details': 'Read the user prompt carefully.'}]

    def _generate_moderate_plan(self, task_desc: str, context: dict) -> list:
        """Gera um plano moderado."""
        # Implementa√ß√£o simulada
        return [
            {'id': 'step1', 'description': 'Analyze context', 'details': 'Read relevant files and scripts.'},
            {'id': 'step2', 'description': 'Create plan', 'details': 'Break down the task into steps.'}
        ]

    def _generate_complex_plan(self, task_desc: str, context: dict) -> list:
        """Gera um plano complexo."""
        # Implementa√ß√£o simulada
        return [
            {'id': 'step1', 'description': 'Read context', 'details': 'Map files, scripts, sensitive areas.'},
            {'id': 'step2', 'description': 'Create plan', 'details': 'Define atomic steps with estimates.'},
            {'id': 'step3', 'description': 'Implement step 1', 'details': 'Apply diffs and commits.'},
            {'id': 'step4', 'description': 'Verify step 1', 'details': 'Run tests, lint, and build.'},
            {'id': 'step5', 'description': 'Open PR', 'details': 'Create a structured pull request.'}
        ]

    def _generate_minimal_diff(self, plan_step: dict, context: dict) -> str:
        """Gera um diff m√≠nimo simulado."""
        # Implementa√ß√£o simulada
        return f"diff --git a/example.py b/example.py\nindex abc..def 100644\n--- a/example.py\n+++ b/example.py\n@@ -1 +1 @@\n-print('old')\n+print('new from {plan_step.get('id')}')\n"

    def _run_lint(self, context: dict) -> dict:
        """Executa linting (simulado)."""
        # Implementa√ß√£o simulada
        return {'success': True}

    def _run_tests(self, context: dict) -> dict:
        """Executa testes (simulado)."""
        # Implementa√ß√£o simulada
        return {'success': True}

    def _run_build(self, context: dict) -> dict:
        """Executa build (simulado)."""
        # Implementa√ß√£o simulada
        return {'success': True}

    def _generate_corrective_patch(self, lint_result: dict, test_result: dict, build_result: dict) -> str:
        """Gera um patch corretivo simulado."""
        # Implementa√ß√£o simulada
        return "patch -p1 < corrective_fix.patch"

    def _generate_pr_body(self, commits: list, test_report: dict, diffs: list) -> str:
        """Gera o corpo do PR."""
        # Implementa√ß√£o simulada
        body = "Este PR aborda as seguintes mudan√ßas:\n\n"
        for commit in commits:
            body += f"- {commit.get('msg', '')}\n"

        body += "\nResultados da Verifica√ß√£o:\n"
        body += f"- Lint: {'Passou' if test_report.get('lint_passed') else 'Falhou'}\n"
        body += f"- Testes: {'Passaram' if test_report.get('tests_passed') else 'Falharam'}\n"
        body += f"- Build: {'Passou' if test_report.get('build_passed') else 'Falhou'}\n"

        if test_report.get('corrective_patches'):
            body += "\nPatches Corretivos Aplicados:\n"
            for patch in test_report['corrective_patches']:
                body += f"- {patch}\n"

        return body

    def _count_layers(self, layer: dict) -> int:
        """Conta o n√∫mero total de layers recursivamente."""
        count = 1
        for child in layer.get('children', []):
            count += self._count_layers(child)
        return count

    def _calculate_max_depth(self, layer: dict, current_depth=1) -> int:
        """Calcula a profundidade m√°xima da √°rvore de layers."""
        max_depth = current_depth
        for child in layer.get('children', []):
            max_depth = max(max_depth, self._calculate_max_depth(child, current_depth + 1))
        return max_depth

    def _expand_layers_recursively(self, layer: dict, max_layers: int, expand_levels: list, current_level=1):
        """Expande layers recursivamente com base nos n√≠veis permitidos."""
        if current_level >= max_layers or not layer.get('children'):
            return

        for child in layer.get('children', []):
            if child['level'] + 1 <= max_layers and child['level'] + 1 in expand_levels:
                # Simula a gera√ß√£o de sub-layers para o pr√≥ximo n√≠vel
                next_level_id_base = f"{child['id']}-next"
                child['children'].append(self.create_hmp_layer(
                    id=f"{next_level_id_base}-1",
                    level=child['level'] + 1,
                    title=f"Sub-task for {child['title'][:30]}...",
                    objective=f"Implementa√ß√£o detalhada de {child['title']}"
                ))
                self._expand_layers_recursively(child, max_layers, expand_levels, current_level + 1)

    def _classify_technical_request(self, user_prompt: str) -> str:
        """Classifica o tipo de requisi√ß√£o t√©cnica baseado no prompt do usu√°rio."""
        user_prompt_lower = user_prompt.lower()

        # Classifica√ß√£o baseada em palavras-chave
        if any(keyword in user_prompt_lower for keyword in ['implementar', 'criar', 'desenvolver', 'adicionar']):
            return 'implementation'
        elif any(keyword in user_prompt_lower for keyword in ['corrigir', 'bug', 'erro', 'fix', 'debug']):
            return 'debugging'
        elif any(keyword in user_prompt_lower for keyword in ['analisar', 'revisar', 'verificar', 'an√°lise']):
            return 'analysis'
        elif any(keyword in user_prompt_lower for keyword in ['otimizar', 'melhorar', 'performance']):
            return 'optimization'
        elif any(keyword in user_prompt_lower for keyword in ['testar', 'test', 'validar']):
            return 'testing'
        else:
            return 'general'

    def _enhance_markdown_for_coder(self, content: str) -> str:
        """
        Melhora a formata√ß√£o markdown para respostas do CODER.
        Adiciona elementos espec√≠ficos para comunica√ß√£o t√©cnica.
        """
        if not content:
            return ''

        enhanced_content = content

        # Melhorar headers com √≠cones funcionais
        header_icons = {
            'an√°lise executiva': 'üéØ',
            'racioc√≠nio hmp': 'üß†',
            'execu√ß√£o': '‚ö°',
            'resultado': 'üìä',
            'artefatos': 'üé®',
            'entreg√°veis': 'üì¶'
        }

        for header, icon in header_icons.items():
            pattern = f"## {header}"
            replacement = f"## {icon} {header.title()}"
            enhanced_content = enhanced_content.replace(pattern, replacement)

        # Melhorar formata√ß√£o de c√≥digo HMP
        enhanced_content = self._enhance_hmp_code_blocks(enhanced_content)

        # Adicionar melhor formata√ß√£o para comandos
        enhanced_content = self._enhance_command_blocks(enhanced_content)

        # Melhorar listas de status
        enhanced_content = self._enhance_status_lists(enhanced_content)

        return enhanced_content

    def _enhance_hmp_code_blocks(self, content: str) -> str:
        """Melhora visualiza√ß√£o de blocos de c√≥digo HMP."""
        import re

        # Melhorar blocos HMP
        hmp_pattern = r'```hmp\n(.*?)\n```'

        def hmp_replacer(match):
            hmp_code = match.group(1)
            return f"""```hmp
# RACIOC√çNIO HMP EXECUTIVO
{hmp_code}
```"""

        return re.sub(hmp_pattern, hmp_replacer, content, flags=re.DOTALL)

    def _enhance_command_blocks(self, content: str) -> str:
        """Melhora visualiza√ß√£o de comandos."""
        import re

        # Melhorar comandos bash
        bash_pattern = r'```bash\n\$ (.*?)\n```'

        def bash_replacer(match):
            command = match.group(1)
            return f"""```bash
# COMANDO EXECUTADO
$ {command}
```"""

        return re.sub(bash_pattern, bash_replacer, content, flags=re.DOTALL)

    def _enhance_status_lists(self, content: str) -> str:
        """Melhora listas com indicadores de status."""
        # Substituir indicadores simples por vers√µes melhoradas
        status_replacements = {
            '- ‚úÖ': '- ‚úÖ **SUCESSO:**',
            '- ‚ùå': '- ‚ùå **ERRO:**',
            '- ‚ö†Ô∏è': '- ‚ö†Ô∏è **ATEN√á√ÉO:**',
            '- üîÑ': '- üîÑ **EM PROGRESSO:**'
        }

        enhanced = content
        for old, new in status_replacements.items():
            enhanced = enhanced.replace(old, new)

        return enhanced