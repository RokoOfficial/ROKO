
# üóÉÔ∏è Arquitetura de Banco de Dados ROKO

## üìã Vis√£o Geral

O sistema ROKO utiliza uma arquitetura h√≠brida inovadora de banco de dados que combina:

- **SQLite** para metadados estruturados e gest√£o de usu√°rios
- **FAISS IndexHNSW** para busca sem√¢ntica vetorial ultra-r√°pida
- **Sistema de Cache Triplo** (L1/L2/L3) com speedup de at√© 100x
- **Re-ranking Contextual** para relev√¢ncia inteligente

## üèóÔ∏è Componentes Principais

### 1. CognitiveMemory (N√∫cleo Principal)
**Localiza√ß√£o**: `ROKO/Memory/cognitive_memory.py`

```python
# Inicializa√ß√£o
memory = CognitiveMemory(
    db_path="roko_nexus.db",           # SQLite principal
    index_path="faiss_index.bin",      # √çndice FAISS
    faiss_dim=3072                     # Dimens√µes embeddings OpenAI
)
```

### 2. UltraCacheSystem (Cache Multicamada)
**Localiza√ß√£o**: `ROKO/Memory/ultra_cache_system.py`

```python
# Cache com 3 camadas otimizadas
cache = UltraCacheSystem(
    max_size=10000,                    # Tamanho m√°ximo
    ttl_hours=24                       # Time-to-live
)
```

### 3. EmbeddingCache (Cache de Embeddings)
**Localiza√ß√£o**: `ROKO/Memory/embedding_cache.py`

```python
# Cache espec√≠fico para embeddings
embedding_cache = EmbeddingCache(
    cache_dir="embedding_cache",       # Diret√≥rio de cache
    max_size=1000,                     # M√°ximo de entradas
    ttl_hours=24                       # Expira√ß√£o
)
```

## üìä Esquema do Banco de Dados

### Tabela: `users`
```sql
CREATE TABLE users (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    username TEXT UNIQUE NOT NULL,
    email TEXT UNIQUE NOT NULL,
    password_hash TEXT NOT NULL,
    created_at REAL NOT NULL,
    last_login REAL,
    is_active INTEGER DEFAULT 1
);
```

### Tabela: `interactions`
```sql
CREATE TABLE interactions (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    user_id INTEGER NOT NULL,
    timestamp REAL DEFAULT CURRENT_TIMESTAMP,
    interaction_type TEXT NOT NULL,
    user_prompt TEXT NOT NULL,
    agent_thoughts TEXT,
    agent_response TEXT,
    embedding BLOB NOT NULL,           -- Vetor de 3072 dimens√µes
    tags TEXT,
    category TEXT,
    importance_score INTEGER DEFAULT 5,
    FOREIGN KEY (user_id) REFERENCES users (id)
);
```

### Tabela: `metadata`
```sql
CREATE TABLE metadata (
    key TEXT PRIMARY KEY,
    value INTEGER
);
```

## ‚ö° Sistema de Cache Triplo

### L1 Cache - Mem√≥ria RAM
- **Speedup**: 100x
- **Armazenamento**: Mem√≥ria vol√°til
- **Uso**: Dados mais acessados

### L2 Cache - Persistente
- **Speedup**: 50x
- **Armazenamento**: Disco local
- **Uso**: Dados frequentemente acessados

### L3 Cache - Sem√¢ntico
- **Speedup**: 20x
- **Armazenamento**: Busca por similaridade
- **Uso**: Conte√∫do semanticamente similar

```python
# Exemplo de uso do cache
result = ultra_cache.get(
    key="user_query",
    content="Como funciona IA?",
    context="tecnologia"
)

if not result:
    # Processar e armazenar
    result = process_complex_query(query)
    ultra_cache.set(
        key="user_query",
        data=result,
        content="Como funciona IA?",
        context="tecnologia"
    )
```

## üéØ FAISS IndexHNSW (Busca Vetorial)

### Configura√ß√£o Otimizada
```python
# Par√¢metros otimizados para embeddings OpenAI
base_index = faiss.IndexHNSWFlat(3072, 32)  # M=32 para qualidade/velocidade
base_index.hnsw.efConstruction = 200        # Constru√ß√£o otimizada
base_index.hnsw.efSearch = 128              # Busca r√°pida
index = faiss.IndexIDMap(base_index)
```

### Performance
- **Dimens√µes**: 3072 (embeddings OpenAI)
- **Algoritmo**: HNSW (Hierarchical Navigable Small World)
- **Complexidade**: O(log N) para busca
- **Precision@10**: >95% comparado com busca exaustiva

## üîß APIs Principais

### Opera√ß√µes de Usu√°rio
```python
# Criar usu√°rio
user_id = memory.create_user(
    username="alice",
    email="alice@example.com", 
    password_hash="hashed_password"
)

# Buscar usu√°rio
user = memory.get_user_by_username("alice")

# Atualizar √∫ltimo login
memory.update_last_login(user_id)
```

### Opera√ß√µes de Intera√ß√£o
```python
# Salvar intera√ß√£o
memory.save_interaction(
    user_id=1,
    interaction_type="pipeline_execution",
    user_prompt="Analise estes dados",
    agent_thoughts="Processando an√°lise...",
    agent_response="An√°lise conclu√≠da",
    embedding=embedding_vector,
    category="analytics",
    tags="data,analysis",
    importance_score=8
)

# Buscar contexto relevante
context = memory.retrieve_context(
    query_embedding=query_vector,
    top_k=5,
    query_context={"category": "analytics"},
    session_context=["data", "analysis"],
    use_reranking=True,
    user_id=1
)
```

### Opera√ß√µes de Busca
```python
# Buscar por categoria
results = memory.search_by_category("analytics", limit=10)

# Buscar por tags
results = memory.search_by_tags(["data", "ai"], limit=10)

# √öltimos chats
chats = memory.get_last_chats(limit=3, user_id=1)
```

## üìà Configura√ß√µes de Performance

### SQLite Otimizado
```sql
PRAGMA busy_timeout = 10000;      -- Timeout para concorr√™ncia
PRAGMA journal_mode = WAL;        -- Write-Ahead Logging
PRAGMA synchronous = NORMAL;      -- Balance performance/safety
PRAGMA cache_size = 10000;        -- Cache de 10MB
PRAGMA temp_store = memory;       -- Temp tables em RAM
```

### Thread Safety
- **Thread-local storage** para conex√µes SQLite
- **RLock** para opera√ß√µes cr√≠ticas
- **WAL mode** para concorr√™ncia sem bloqueios
- **Connection pooling** autom√°tico

## üõ†Ô∏è Manuten√ß√£o e Otimiza√ß√£o

### Limpeza Autom√°tica
```python
# Remover intera√ß√µes antigas (mant√©m importantes)
deleted = memory.cleanup_old_memories(
    days_old=30,
    keep_important=True  # Mant√©m score > 7
)

# Reconstruir √≠ndice FAISS
memory._rebuild_index()
```

### Valida√ß√£o de Integridade
```python
# Verificar sa√∫de do sistema
health = memory.validate_system_integrity()
print(f"Status: {health['status']}")
print(f"Issues: {health['issues']}")

# Estat√≠sticas detalhadas
stats = memory.get_memory_stats()
print(f"Total interactions: {stats['total_interactions']}")
print(f"FAISS vectors: {stats['faiss_vectors']}")
print(f"Cache hit rate: {stats['cache_performance']['hit_rate']}")
```

## üìä M√©tricas de Performance

### Benchmarks T√≠picos
- **Insert Rate**: ~1000 intera√ß√µes/segundo
- **Query Time**: <50ms para busca sem√¢ntica
- **Cache Hit Rate**: 85-95%
- **Memory Usage**: ~100MB para 100k intera√ß√µes
- **Disk Usage**: ~500MB para 100k intera√ß√µes + embeddings

### Estat√≠sticas em Tempo Real
```python
stats = memory.get_memory_stats()
{
    "total_interactions": 15847,
    "faiss_vectors": 15847,
    "cache_performance": {
        "hit_rate": "94.67%",
        "estimated_speedup": 92.2
    },
    "index_info": {
        "type": "IndexIDMap",
        "total_vectors": 15847,
        "dimensions": 3072
    }
}
```

## üîí Seguran√ßa e Backup

### Backup Autom√°tico
- Backup antes de opera√ß√µes cr√≠ticas
- Verifica√ß√£o de integridade p√≥s-salvamento
- Recupera√ß√£o autom√°tica de falhas

### Seguran√ßa
- Senhas hasheadas (nunca plaintext)
- Valida√ß√£o de input em todas as opera√ß√µes
- Isolamento de dados por usu√°rio
- Logs de auditoria completos

## üö® Troubleshooting

### Problemas Comuns

#### 1. √çndice FAISS Corrompido
```python
# Detectar e corrigir
if memory.index.ntotal == 0:
    memory._rebuild_index()
```

#### 2. Embeddings com Dimens√£o Incorreta
```python
# Verificar dimens√µes
if embedding.shape[0] != 3072:
    print(f"Dimens√£o incorreta: {embedding.shape[0]}")
```

#### 3. Database Lock
```python
# Configurar timeout maior
conn.execute("PRAGMA busy_timeout = 30000;")
```

#### 4. Cache Miss Alto
```python
# Verificar TTL e tamanho
cache_stats = ultra_cache.get_cache_stats()
if cache_stats["hit_rate"] < 80:
    # Aumentar TTL ou tamanho do cache
    pass
```

### Logs de Debug
```python
import logging
logging.basicConfig(level=logging.DEBUG)

# Logs espec√≠ficos do sistema
logger = logging.getLogger('CognitiveMemory')
logger.setLevel(logging.DEBUG)
```

## üîÑ Migrations e Versionamento

### Migra√ß√µes Autom√°ticas
O sistema detecta e aplica migra√ß√µes automaticamente:

```python
# Verificar colunas existentes
cursor.execute("PRAGMA table_info(interactions)")
columns = [column[1] for column in cursor.fetchall()]

# Adicionar colunas se n√£o existirem
if 'tags' not in columns:
    cursor.execute("ALTER TABLE interactions ADD COLUMN tags TEXT")
    
if 'category' not in columns:
    cursor.execute("ALTER TABLE interactions ADD COLUMN category TEXT")
    
if 'importance_score' not in columns:
    cursor.execute("ALTER TABLE interactions ADD COLUMN importance_score INTEGER DEFAULT 5")
```

## üìö Refer√™ncias e Links

- **SQLite WAL Mode**: https://sqlite.org/wal.html
- **FAISS Documentation**: https://github.com/facebookresearch/faiss
- **OpenAI Embeddings**: https://platform.openai.com/docs/guides/embeddings
- **Thread Safety**: https://docs.python.org/3/library/threading.html

---

**Nota**: Esta arquitetura foi projetada para alta performance em aplica√ß√µes de IA com busca sem√¢ntica intensiva. O sistema √© auto-otimizante e requer manuten√ß√£o m√≠nima.
