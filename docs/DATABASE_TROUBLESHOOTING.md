
# üö® Troubleshooting - Banco de Dados ROKO

## üîç Diagn√≥stico R√°pido

### Script de Verifica√ß√£o Autom√°tica
```python
from Memory import CognitiveMemory

def quick_health_check():
    """Verifica√ß√£o r√°pida da sa√∫de do banco."""
    memory = CognitiveMemory()
    
    # 1. Validar integridade
    health = memory.validate_system_integrity()
    print(f"üè• Status: {health['status']}")
    
    if health['issues']:
        print("‚ö†Ô∏è  Problemas detectados:")
        for issue in health['issues']:
            print(f"   - {issue}")
    
    # 2. Estat√≠sticas b√°sicas
    stats = memory.get_memory_stats()
    print(f"üìä Intera√ß√µes: {stats['total_interactions']}")
    print(f"üß† Vetores FAISS: {stats['faiss_vectors']}")
    print(f"üíæ Cache hit rate: {stats['cache_performance']['hit_rate']}")
    
    # 3. Verificar arquivos essenciais
    import os
    files_to_check = [
        "roko_nexus.db",
        "faiss_index.bin"
    ]
    
    for file in files_to_check:
        if os.path.exists(file):
            size = os.path.getsize(file) / (1024*1024)  # MB
            print(f"‚úÖ {file}: {size:.2f} MB")
        else:
            print(f"‚ùå {file}: Arquivo n√£o encontrado")
    
    return health

# Executar verifica√ß√£o
quick_health_check()
```

## üêõ Problemas Comuns e Solu√ß√µes

### 1. Erro: "Database is locked"

**Sintoma**: `sqlite3.OperationalError: database is locked`

**Causas**:
- M√∫ltiplas conex√µes simult√¢neas
- Processo anterior n√£o fechou conex√£o
- Arquivo corrompido

**Solu√ß√µes**:
```python
# Solu√ß√£o 1: Aumentar timeout
memory._get_connection().execute("PRAGMA busy_timeout = 30000;")

# Solu√ß√£o 2: For√ßar fechamento de conex√µes
memory.close_connections()

# Solu√ß√£o 3: Verificar processos usando o arquivo
import subprocess
result = subprocess.run(['lsof', 'roko_nexus.db'], capture_output=True, text=True)
print(result.stdout)
```

### 2. Erro: "FAISS index dimension mismatch"

**Sintoma**: `RuntimeError: Wrong vector dimension`

**Causas**:
- Embedding com dimens√£o incorreta
- √çndice corrompido
- Mudan√ßa no modelo de embedding

**Solu√ß√µes**:
```python
# Verificar dimens√µes
embedding = get_embedding("test")
print(f"Dimens√£o do embedding: {embedding.shape[0]}")
print(f"Dimens√£o esperada: {memory.faiss_dim}")

# Reconstruir √≠ndice se necess√°rio
if embedding.shape[0] != memory.faiss_dim:
    memory._rebuild_index()
```

### 3. Cache com Low Hit Rate (<80%)

**Sintoma**: Performance lenta, hit rate baixo

**Diagn√≥stico**:
```python
from Memory import ultra_cache

stats = ultra_cache.get_cache_stats()
print(f"Hit rate: {stats['hit_rate']}")
print(f"L1 hits: {stats['l1_hits']}")
print(f"L2 hits: {stats['l2_hits']}")
print(f"L3 hits: {stats['l3_hits']}")
print(f"Misses: {stats['cache_misses']}")
```

**Solu√ß√µes**:
```python
# Aumentar TTL
ultra_cache.ttl_hours = 48

# Aumentar tamanho do cache
ultra_cache.max_size = 20000

# Limpar cache corrompido
ultra_cache.memory_cache.clear()
ultra_cache.persistent_cache.clear()
```

### 4. Erro: "Memory usage too high"

**Sintoma**: Uso excessivo de RAM

**Diagn√≥stico**:
```python
import psutil
import os

# Uso de mem√≥ria do processo
process = psutil.Process(os.getpid())
memory_info = process.memory_info()
print(f"RSS: {memory_info.rss / 1024 / 1024:.2f} MB")
print(f"VMS: {memory_info.vms / 1024 / 1024:.2f} MB")

# Tamanho dos caches
print(f"Memory cache entries: {len(ultra_cache.memory_cache)}")
print(f"Embedding cache entries: {len(memory.embedding_cache.memory_cache)}")
```

**Solu√ß√µes**:
```python
# Reduzir tamanho dos caches
ultra_cache.max_size = 5000
memory.embedding_cache.max_size = 500

# Limpeza for√ßada
ultra_cache._cleanup_if_needed()
memory.embedding_cache._cleanup_old_entries()

# Limpeza de intera√ß√µes antigas
memory.cleanup_old_memories(days_old=7, keep_important=True)
```

### 5. Erro: "Embedding cache corruption"

**Sintoma**: Erros ao carregar embeddings do cache

**Verifica√ß√£o**:
```python
import os
cache_dir = "embedding_cache"

# Listar arquivos corrompidos
for filename in os.listdir(cache_dir):
    if filename.endswith('.npy'):
        file_path = os.path.join(cache_dir, filename)
        try:
            embedding = np.load(file_path)
            if embedding.shape[0] != 3072:
                print(f"Arquivo corrompido: {filename} (dim: {embedding.shape[0]})")
        except Exception as e:
            print(f"Erro ao carregar {filename}: {e}")
```

**Solu√ß√µes**:
```python
# Limpar cache de embeddings
memory.embedding_cache.clear()

# Remover arquivos corrompidos
import os
import glob

corrupted_files = glob.glob("embedding_cache/*.npy")
for file in corrupted_files:
    try:
        embedding = np.load(file)
        if embedding.shape[0] != 3072:
            os.remove(file)
            print(f"Removido: {file}")
    except:
        os.remove(file)
        print(f"Removido (corrompido): {file}")
```

## üîß Ferramentas de Manuten√ß√£o

### Script de Repara√ß√£o Autom√°tica
```python
def auto_repair_database():
    """Repara problemas comuns automaticamente."""
    from Memory import CognitiveMemory
    import os
    
    print("üîß Iniciando repara√ß√£o autom√°tica...")
    
    try:
        memory = CognitiveMemory()
        
        # 1. Verificar integridade
        health = memory.validate_system_integrity()
        
        if health['status'] == 'error':
            print("‚ùå Erro cr√≠tico detectado")
            return False
        
        # 2. Sincronizar √≠ndice FAISS
        if 'Embeddings n√£o indexados' in str(health['issues']):
            print("üîÑ Sincronizando √≠ndice FAISS...")
            memory._sync_index()
        
        # 3. Reconstruir √≠ndice se necess√°rio
        if memory.index.ntotal == 0 and health['total_interactions'] > 0:
            print("üèóÔ∏è  Reconstruindo √≠ndice FAISS...")
            memory._rebuild_index()
        
        # 4. Limpar caches
        print("üßπ Limpando caches...")
        memory.embedding_cache._cleanup_old_entries()
        
        # 5. Otimizar SQLite
        conn = memory._get_connection()
        print("‚ö° Otimizando SQLite...")
        conn.execute("VACUUM;")
        conn.execute("ANALYZE;")
        conn.commit()
        
        print("‚úÖ Repara√ß√£o conclu√≠da com sucesso!")
        return True
        
    except Exception as e:
        print(f"‚ùå Erro durante repara√ß√£o: {e}")
        return False

# Executar repara√ß√£o
auto_repair_database()
```

### Backup e Restaura√ß√£o
```python
def backup_database():
    """Cria backup completo do banco."""
    import shutil
    import datetime
    
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    backup_dir = f"backup/roko_backup_{timestamp}"
    os.makedirs(backup_dir, exist_ok=True)
    
    # Backup SQLite
    shutil.copy2("roko_nexus.db", f"{backup_dir}/roko_nexus.db")
    
    # Backup FAISS
    if os.path.exists("faiss_index.bin"):
        shutil.copy2("faiss_index.bin", f"{backup_dir}/faiss_index.bin")
    
    # Backup cache de embeddings
    if os.path.exists("embedding_cache"):
        shutil.copytree("embedding_cache", f"{backup_dir}/embedding_cache")
    
    print(f"‚úÖ Backup criado em: {backup_dir}")
    return backup_dir

def restore_database(backup_dir):
    """Restaura banco de backup."""
    import shutil
    
    # Parar sistema
    memory.close_connections()
    
    # Restaurar arquivos
    shutil.copy2(f"{backup_dir}/roko_nexus.db", "roko_nexus.db")
    
    if os.path.exists(f"{backup_dir}/faiss_index.bin"):
        shutil.copy2(f"{backup_dir}/faiss_index.bin", "faiss_index.bin")
    
    if os.path.exists(f"{backup_dir}/embedding_cache"):
        if os.path.exists("embedding_cache"):
            shutil.rmtree("embedding_cache")
        shutil.copytree(f"{backup_dir}/embedding_cache", "embedding_cache")
    
    print("‚úÖ Banco restaurado com sucesso!")
```

## üìä Monitoramento Cont√≠nuo

### Script de Monitoramento
```python
def monitor_database():
    """Monitora sa√∫de do banco em tempo real."""
    import time
    import json
    
    while True:
        try:
            memory = CognitiveMemory()
            stats = memory.get_memory_stats()
            
            # M√©tricas importantes
            metrics = {
                "timestamp": time.time(),
                "total_interactions": stats['total_interactions'],
                "faiss_vectors": stats['faiss_vectors'],
                "cache_hit_rate": float(stats['cache_performance']['hit_rate'].rstrip('%')),
                "memory_cache_size": len(memory.embedding_cache.memory_cache)
            }
            
            # Alertas
            if metrics['cache_hit_rate'] < 70:
                print(f"‚ö†Ô∏è  Cache hit rate baixo: {metrics['cache_hit_rate']:.1f}%")
            
            if metrics['total_interactions'] != metrics['faiss_vectors']:
                print(f"‚ö†Ô∏è  Dessincronia: {metrics['total_interactions']} vs {metrics['faiss_vectors']}")
            
            # Log m√©tricas
            with open("logs/db_metrics.jsonl", "a") as f:
                f.write(json.dumps(metrics) + "\n")
            
            time.sleep(60)  # Verificar a cada minuto
            
        except Exception as e:
            print(f"‚ùå Erro no monitoramento: {e}")
            time.sleep(10)
```

## üìû Suporte e Escala√ß√£o

### Logs de Debug
```python
# Ativar logging detalhado
import logging
logging.basicConfig(level=logging.DEBUG)

# Logger espec√≠fico para mem√≥ria
memory_logger = logging.getLogger('CognitiveMemory')
memory_logger.setLevel(logging.DEBUG)

# Logger para cache
cache_logger = logging.getLogger('UltraCacheSystem')
cache_logger.setLevel(logging.DEBUG)
```

### Coleta de Informa√ß√µes para Suporte
```python
def collect_debug_info():
    """Coleta informa√ß√µes para suporte t√©cnico."""
    import platform
    import sys
    
    info = {
        "system": {
            "platform": platform.platform(),
            "python_version": sys.version,
            "memory_available": psutil.virtual_memory().available // 1024 // 1024  # MB
        },
        "roko": {
            "database_health": memory.validate_system_integrity(),
            "memory_stats": memory.get_memory_stats(),
            "cache_stats": ultra_cache.get_cache_stats()
        },
        "files": {
            "db_size": os.path.getsize("roko_nexus.db") if os.path.exists("roko_nexus.db") else 0,
            "faiss_size": os.path.getsize("faiss_index.bin") if os.path.exists("faiss_index.bin") else 0
        }
    }
    
    # Salvar relat√≥rio
    with open("debug_report.json", "w") as f:
        json.dump(info, f, indent=2)
    
    print("üìã Relat√≥rio de debug salvo em: debug_report.json")
    return info
```

---

**üÜò Emerg√™ncia**: Se o sistema estiver completamente inacess√≠vel, delete os arquivos `roko_nexus.db` e `faiss_index.bin` para reinicializa√ß√£o completa (perda de dados).
